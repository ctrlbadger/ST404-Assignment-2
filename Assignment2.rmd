---
title: "ST404 Assignment 2"
author: "Frank Or, Remos Gong, Sam Glanfield, Thomas Broadbent"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2: default
  pdf_document: 
    number_sections: true
fontsize: 11pt
linestretch: 1.5
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  fig.align = "center",
	fig.width = 7,
  echo = TRUE)
library(bookdown)
library(knitr)
```

```{r libraries, include=FALSE}
library(dplyr)
library(car)
library(tidyr)
library(glmnet)
```

\pagebreak 

# Findings

## Summary of EDA

In the previous EDA report we have explored the data set and we will perform data cleaning and variable transformations before constructing a linear model. 

---Might Merge in one if run out of space?

### Missing/Incorrect Values and Outliers

We identified 152 missing values in __Percent Employed 16 and Over__. Since they have no pattern, we deduced that these values are missing at random (MCAR). We used other complete data entries to calculate what we would expect these values to be and impute them back to our data set. We also identified values in __Average Household Size__ that unreasonably small. We believed this is an error in data entry and we scaled them by 100 in order to make it normal.
For outliers, We removed __Williamsburg City, Virginia__ because of its high __Incidence Rate__ but low __Death Rate__, hence high influence to our model. 

### Transformations

In order to fulfill the model assumptions, namely __Linearity__, __Homoscedasticity__, __Normality__, we performed log transforms for two variables: __Median Income__ and __Percent Black__ which suffered the most among all variables. Although the transformations did not cure the problems, they result in improvements in linearity and normality, reducing heteroscedasticity for both said variables. For other variables, we deduced that they are good enough to fulfill the model assumptions and hence did not perform any transformations for model simplicity.

--Might add plots?

### Multicollinearity

We have discovered a few pairs or clusters of predictor variables that are highly correlated with each other. The obvious ones are __Median Age Female__ and __Median Age Male__, __Percent Married__ and __Percent Married Households__, __Binned Income__ and __Median Income__. These variables measure the same force and hence at least one in the pairs are expected to be excluded in our modelling. 

### Correlation with Death Rate

While most predictor variables have absolute correlation coefficient roughly 0.3 to 0.4 with death rate, Median Age Male, Median Age Female and Average Household Size have almost zero correlation coefficient. We expect our model to not include these uncorrelated variables.

## Major Determinants of Mortality Rates

From our model building process we have identified that the major determinants in high mortality rates of cancer in the US are: __Incidence Rate, Percent Unemployed 16 and Over, Percent Employer Provided Private Coverage and Percent Black__. Whereas, the major determinants in low mortality rates are: __Percent Employed 16 and Over, Percent Private Coverage, Education Levels and Median Income__.

## Modelling Approach

We used Stepwise Regression, RIDGE Regression and LASSO Regression to build our model. We compared the outputs and the variables selections of these models. We also analyse the goodness of fits of these models using Leave-one-out cross validation, $R^2$ statistics and residuals analysis.
We did not include __Geography__ and __Binned Income__ and we were using the __Log Percent Black__ and __Log Median Income__ in the following analysis.

---I found the following sections very tricky to write up. Might need a better structure. NEED HELP!

### Stepwise Regression

We used __Bayesian Information Criteria(BIC)__ in our analysis. This penalises additional parameters harder than __Akaike information criterion(AIC)__ which agrees with parsimony in our modelling. We performed forward, backward and hybrid stepwise regression. In all of the models that were generated we notice that we have groups of parameters that are similar and hence induce multicollinearity in the models. For example, we see both __Percent Married__ and __Percent Married Households__ in the models and as stepwise methods do not account for multicollinearity this causes increases in the variance of our coefficient estimates and makes the model sensitive to changes, thus reducing drastically the predictive power of the model. In order to address the issue of multicollinearity we apply Ridge and Lasso techniques which account for this.

### RIDGE Regression

### LASSO Regression

The suggested model contains eight variables which is the simplest model among our approaches. Since the purpose of this report is to reveal patterns in the mortality rate, we believed it is best to choose a simple model for stronger explanatory power.

### Final Model Choice and Diagnostics

We used residuals plot and QQ plot to diagnose the stepwise regression model. Both plots are satisfactory, agreeing with model assumptions.

We also performed Leave-one-out cross-validation for this stepwise model, which gives $R^2$ value of $0.4621$.
We did the same cross-validation for our Ridge and Lasso model.
The Ridge model gives $R^2$ value of $0.4436$.
The Lasso model gives $R^2$ value of $0.4441$.

The stepwise model fits the observed data the best among all our models. The Lasso and the Ridge model is similar in this sense.
However, the Lasso model contains the least number of predictor variables and we believed this is the most important criterion.
Thus from our analysis briefly outlined above and in the next section we recommend the following model, as seen below, due to its mix of predictive and explanatory power as well as being a simple model.

$DeathRate = 470.47 + 0.23IncidenceRate - 0.25PctEmployed16\_Over + 0.029PctUnemployed16\_Over - 0.32PctPrivateCoverage + 0.21PctEmpPrivCoverage - 10.06Edu18\_24 + 0.90log(PctBlack) - 32.34log(MedianIncome)$

## Areas that do not conform the general pattern

We do see examples of counties that do not conform to the general pattern with unusually high or low mortality rates. One example we have is 'Williamsburg City, Virginia' where we see a high incidence rate of 1014 yet a comparatively small death rate of 162, however we see that it's percent private coverage is 19% above the US average and the median male and female ages of 26 and 24 respectively are considerably lower than the median US ages, potentially being causes for this low death rate. Similarly, we see from the average residual map that in particular the 3 states Utah (Average of -22), Idaho (Average of -19) and Colorado (Average of -18) all have high residual averages and as they are negative this implies that the model is overfitting for these states and thus these states don't conform to the general pattern. However, as the model if overfitting and we are estimating death rate this isnt a cause for concern as we know the average death rates for these states is highly likely to be lower than what the model predicts. It is also important to note that these all lie in a similar region and in general we see that the majority of states on the west coast have an average negative residual, so the model overfits for these states, hwereas on the east coast and central we see positive average residuals, the model is underfitting these states. With the main staes of concern for overfitting with an average residual of 14 each for Oklahoma and Arkansas and an average of 13 in the District of Columbia.

\pagebreak 

# Statistical Methodology

```{r loadData, include=FALSE}
## Included Libraries
# For pipe operator and general mutation
load('cancer.rdata')
```

We first combined our results and findings from our preliminary EDA which is mainly discussed in [Outliers](#outliers) and [Transformations](#transformations).

## Outcomes of EDA

### Missing Or Incorrect Values

We also see counties with missing values in Percentage Employed 16 and Over and we conclude that the data is Missing Completely at Random. In order to rectify this we impute this data by fitting a linear regression model of Percentage Employed 16 and Over on the remaining variables to estimate what these values would be. (See Appendix 2.1.1). 

```{r impute, include=FALSE}
# Impute the missing data seen in the data set
mod1=lm(PctEmployed16_Over~+incidenceRate+medIncome+binnedInc+povertyPercent+MedianAgeMale+MedianAgeFemale+AvgHouseholdSize+PercentMarried+PctUnemployed16_Over+PctPrivateCoverage+PctEmpPrivCoverage+PctPublicCoverage+PctBlack+PctMarriedHouseholds+Edu18_24,cancer)
missdf = cancer[which(is.na(cancer$PctEmployed16_Over)==TRUE),]
imputed = predict(mod1,missdf)
cancer[which(is.na(cancer$PctEmployed16_Over)==TRUE),"PctEmployed16_Over"] = imputed
```

For counties with Average Household Size less than one we took the decision to scale the transformations by 100 and keep them in the dataset. This fixed the normality of AvgHouseholdSize as shown in the histogram.

```{r averageHouseholdSize, echo=FALSE,fig.cap="Histograms before(Left) and after(Right)", fig.asp=0.5}
# Scale average household sizes that are less than 1 by 100
par(mfrow=c(1,2))
hist(cancer$AvgHouseholdSize, breaks=30, xlab="AvgHouseholdSize", main="Histogram of AvgHouseholdSize")
cancer[which(cancer$AvgHouseholdSize < 1), ]$AvgHouseholdSize <- 
  100*cancer[which(cancer$AvgHouseholdSize < 1), ]$AvgHouseholdSize
hist(cancer$AvgHouseholdSize, breaks=30, xlab="AvgHouseholdSize", main="Histogram of AvgHouseholdSize")
```

### Outliers {#outliers}

Counties with high Incidence Rates, namely 'Union County, Florida' and 'Williamsburg City, Virginia'. We looked into the cook's distance plots and noticed only 'Williamsburg City, Virginia' has large cook's distance and hence influential. The first cook's distance plot used a linear model with only incidenceRate as the predictor variable. The second used all the numerical variables. We concluded although 'Union County, Florida' has high leverage, it is not influential and hence should be kept in our data set.
(See Appendix 2.1.2)

```{r incidenceRateRemoval, echo=FALSE, fig.asp=0.5, fig.cap="Cook's distance plots of models with only incidence Rate(Left) and all variables(Right)"}
# Cook's distance Plot
par(mfrow=c(1,2))
plot(lm(deathRate ~ incidenceRate,data=cancer),4)
plot(lm(deathRate ~ .,data=cancer[-c(1,4)]),4)
# Removing outlier incidence rates 'Williamsburg City, Virginia'
cancer <- filter(cancer, incidenceRate <= 850)
```

### Transformations {#transformations}

We transform Percent Black by first shifting the values upwards by 0.05, to ensure we have no zero values, then take a log transform. We also transform the Median Income by again taking a log transformation. We do these transformations to ensure the data is not heavily skewed and allow for a more accurate model. (See Appendix 2.1.3)

```{r transformations, include=FALSE}
# Log transforming the heavily skewed distributions of PctBlack and medIncome
cancer$logpctblack = log(cancer$PctBlack+0.05)
cancer$logmedincome = log(cancer$medIncome)
```

The following residual plots show the improvements in homoscedasticity in PctBlack and medIncome after log-transform respectively.

```{r heteroscedasticity1,echo=FALSE, fig.asp=0.5, fig.cap="Residuals plot Percent Black(Left) and Log Percent Black(Right"}
# Showing improvements in homoscedasticity in PctBlack
par(mfrow=c(1,2))
plot(lm(deathRate~PctBlack,data=cancer),1)
plot(lm(deathRate~logpctblack,data=cancer),1)
```
---Might add other improvements 

## Modelling Approach and Variable Selection

### AIC and BIC Forward and Backward Variable Selection

We perform forward, backward and hybrid stepwise regression according to BIC to ensure a more parsimonious model. We see that the models generated for BIC are all the same. We see that in the BIC model has 11 variables and in Table 1 we see the estimates for these variables.

```{r stepwise, include=FALSE}
# Below we perform stepwise regression for both AIC and BIC
# cancermodel = cancer[,-c(1,3,15)]
cancermodel <- cancer %>% select(
  !c("Geography", "medIncome", "binnedInc", "PctBlack"))
c0=lm(deathRate~1,cancermodel)
cmax=lm(deathRate~.,cancermodel)
forwardoptimalBIC = step(c0,direction="forward",
scope=list("lower"=c0,"upper"=cmax),trace=0,k=log(3045))
backwardoptimalBIC = step(cmax,direction="backward",
scope=list("lower"=c0,"upper"=cmax),trace=0,k=log(3045))
hybridoptimalBIC = step(c0,direction="both",
scope=list("lower"=c0,"upper"=cmax),trace=0,k=log(3045))
```

For the model generated we see from the summary output, with strong evidence, that all the coefficients are different from zero. From observing the output we see that we would expect there to be multicollinearity in these models due to variables that measure similar or opposite quantities, for example Percent Married and Percent Married Households.

```{r summaryAICBIC, include=FALSE}
# We compute the summaries of the stepwise model
summary(hybridoptimalBIC)
```

We compute the Variance Inflation Factors (VIF) for the model and see that there are numerous values that are at least 5 indicating that we have multicollinearity. Specifically, we see a VIF of at least 10 in Percent Married and a VIF of 8 in Percent Married Households. As well as in log(Median Income), Percent Employed 16 and Over, Percent Employers Private Coverage and Percent Private Coverage. Due to this frequent multicollinearity between the predictors in the stepwise model this suggests that the stepwise model is not a suitable approach as multicollinearity is not taken into account and thus we proceed below with Ridge Regression and Lasso to reduce the effects of multicollinearity on the model.

To complete the section on stepwise regression we perform leave one out cross validation (in order to compute the $R^2$ of the stepwise models and also the Root Mean Squared Error (See Appendix 2.2.1). This allows us to compare these models with the Ridge and Lasso models we generate in the enxt sections. Performing this we see in the stepwise model we have an $R^2$ value of 0.4623.

```{r LOOCVforStepwise, cache=TRUE, include=FALSE}
library(caret)
#specify the cross-validation method
#fit a regression model and use LOOCV to evaluate performance
loocv <- function(lm1, data=cancer) {
  ctrl <- trainControl(method = "LOOCV")
  xnam <- names(lm1$coefficients)[-1]
  fmla <- as.formula(paste("deathRate ~ ", paste(xnam, collapse= "+")))
  model <- train(fmla, data = data, method = "lm", trControl = ctrl)
  return(model)
}
hybridoptimalBIC.loocv <- loocv(hybridoptimalBIC,data=cancermodel)
```

### RIDGE Regression

To address the multi-collinearity present in the data we assess the viability of a RIDGE Regression Model. For this we fit all continuous variables as predictors using the `glmnet` library. 

The trace shows that the ridge penalisation method reduces many variables close to 0 but does not remove any variables from the model itself. (See Apendix 2.2.2)

```{r Ridge 1, include=FALSE}
library(glmnet)

# Create Data Matrix
cancer.dm <- cancer %>% 
  select(!c("Geography", "medIncome", "binnedInc", "PctBlack", "deathRate")) %>%
  data.matrix()

lm.ridge <- glmnet(cancer.dm, cancer$deathRate, alpha=0)
lm.ridge.cv <- cv.glmnet(cancer.dm, cancer$deathRate, alpha=0)

# Create Model Plot Func
traceLogLambda <- function(lm1, lm1.cv, ylim=NULL, sub=NULL) {
  plot(lm1,"lambda",label = T, ylim=ylim)
  abline(v=log(lm1.cv$lambda.1se),col="red")
  abline(v=log(lm1.cv$lambda.min),col="blue")
  legend("bottomright",legend=c("Minimum lambda", "1 standard error larger lambda"),lty=c(1,1),col=c("blue","red"), ins=0.05)
  title(sub=sub)
  
}

traceLogLambda(lm.ridge, lm.ridge.cv, ylim=c(-20, 1), sub="RIDGE trace against log(lambda)")

lm.ridge.1se <- glmnet(cancer.dm, cancer$deathRate, alpha = 0, 
               lambda = lm.ridge.cv$lambda.1se)


lm.ridgefitted <- predict(lm.ridge.1se, newx=cancer.dm)
scatter.smooth(cancer$deathRate - lm.ridgefitted, x=lm.ridgefitted,
               xlab="Fitted", ylab="Residuals", 
               sub="Residuals vs Fitted for RIDGE Model")

```

Fitting a ridge model and using the value of $\lambda$ one standard error further away from the minimum does not remove any of the terms from the model and gives the coefficients as seen in Table 1. We also include the parameter estimates when the parameters are scaled to highlight how significant the parameter is.


```{r Ridge Loo, include=FALSE, cache=TRUE}
library(parallel)
library(foreach)
library(doParallel)
numCores <- detectCores()
registerDoParallel(numCores) 

n <- dim(cancer)[1]
dev.ratios <- rep(NA, n)
dev.ratios1 <- rep(NA, n)
lm.ridge.cv <- cv.glmnet(cancer.dm, cancer$deathRate, alpha=0, nfolds=n, parallel=TRUE)

lm.ridge.cv$lambda.1se

for (i in 1:n) {
  lm.ridge.1se <- glmnet(cancer.dm[-i,], cancer$deathRate[-i], alpha = 0, 
               lambda = lm.ridge.cv$lambda.1se)
  
  
  dev.ratios1[i] <- lm.ridge.1se$dev.ratio
  # lm.residuals <- predict(lm.ridge.1se, newx=cancer.dm[-i, ]) - cancer$deathRate[-i]
  # dev.ratios[i] <- 1 - sum(lm.residuals^2)/sum((cancer$deathRate[-i] -mean(cancer$deathRate[-i]))^2) 
  
}
mean(dev.ratios1)

```

\scriptsize

```{r Ridge estimate, include=FALSE}
library(knitr)


a <- data.frame(sapply(round(coef(lm.ridge.1se), 3), FUN=identity))
colnames(a) <- "Parameter Estimates"

# cancer.dm.scale <- cancer %>%
#   select(!c("Geography", "medIncome", "binnedInc", "PctBlack", "deathRate")) %>%
#   scale %>%
#   data.matrix()
# lm.ridge.scale.cv <- cv.glmnet(cancer.dm.scale, scale(cancer$deathRate), alpha = 0)
# lm.ridge.1se.scale <- glmnet(cancer.dm.scale, scale(cancer$deathRate), alpha = 0, lambda = lm.ridge.scale.cv$lambda.1se)
# a$"Scaled Parameter Estimates" <-sapply(round(coef(lm.ridge.1se.scale), 3), FUN=identity)

rownames(a) <- rownames(round(coef(lm.ridge.1se), 3))
```

\normalsize

Performing a leave one out cross validation gives an $R^2$ statistic of $0.4438$. Which is similar to the previous step wise regression method and is harder to diagnose therefore we conclude that it it is not a suitable model.

### LASSO Regression 

```{r Lasso data cleaning,echo=FALSE}
# cancer.lasso.dm <- cancer %>%
#   select(!c("Geography", "medIncome", "binnedInc", "PctBlack", "deathRate","MedianAgeFemale","PctMarriedHouseholds")) %>%
#   data.matrix()
cancer.lasso.dm <- cancer %>%
  select(!c("Geography", "medIncome", "binnedInc", "PctBlack", "deathRate")) %>%
  data.matrix()
```

We used cross-validation from the glmnet library which leaves out a 10th of the data every time.
We produced the following plot of mean-squared error against log(lambda). We decided to use the 1-standard-error-lambda because this likely to shrink some predictor variables to zero, performing variable selection. We prefer a simpler model. (See Apendix 2.2.3)

```{r Lasso cv, echo=FALSE, fig.asp=0.5, fig.cap="Mean-squared error against log(lambda)"}
set.seed((934))
lm.lasso <-glmnet(cancer.lasso.dm,cancer$deathRate,alpha=1)
lm.lasso.cv <- cv.glmnet(cancer.lasso.dm,cancer$deathRate,alpha=1)
plot(lm.lasso.cv)
abline(v=log(lm.lasso.cv$lambda.1se),col="red")
abline(v=log(lm.lasso.cv$lambda.min),col="blue")
legend("topright",legend=c("Minimum lambda", "1 standard error larger lambda"),lty=c(1,1),col=c("blue","red"), ins=0.1)
lm.lasso.cv$lambda.1se
lm.lasso.1se <- glmnet(cancer.lasso.dm,cancer$deathRate,lambda = lm.lasso.cv$lambda.1se,alpha=1)

lm.lasso.1se.fitted <- predict(lm.lasso.1se, newx=cancer.lasso.dm)
lm.lasso.1se.residuals <- cancer$deathRate - lm.lasso.1se.fitted
```

We produced a plot that shows a trace of each parameter estimate for different values of log(lambda). (See Fig. 4 and Apendix 2.2.3)
We scaled the model for a better visual interpretation. (See Fig. 5 and Apendix 2.2.3)

```{r Lasso trace, echo=FALSE, fig.cap="Trace of parameter estimates for different lambda",fig.asp=0.5}
lm.lasso.scaled<-glmnet(scale(cancer.lasso.dm),cancer$deathRate,alpha=1)
traceLogLambda(lm.lasso.scaled,lm.lasso.cv,ylim=c(-10,10), sub="LASSO trace against log(lambda)")
```
The Lasso regression using 1-standard-error-lambda produces the following parameter estimates. Alongside we see the parameter estimates for Ridge regression and stepwise regression to allow for easier comparison of the models.

\scriptsize
```{r,echo=FALSE}
b <- data.frame(sapply(round(coef(lm.lasso.1se), 3), FUN=identity))
colnames(b) <- "Parameter Estimates"
rownames(b) <- rownames(round(coef(lm.lasso.1se), 3))
#Create matrix of stepwise coefficients
c = as.data.frame(c(507.558,0.227,0.000,0.000,-0.421,0.000,1.285,-0.821,0.000,-0.685,0.899,0.000,-0.973,-11.839,1.405,-32.750))
y=cbind(a,b,c)
colnames(y) = c("Ridge","LASSO","Stepwise")
kable(y, caption="Parameter Estimates of the Models")
```
\normalsize

### Interpretation

From the estimates output above, the Lasso regression eliminates a considerable number of predictor variables. The Lasso regression model has the following non-zero predictor estimates: __Incidence Rate__, __Percent Employed 16 and Over__, __Percent Private Coverage__,  __Percent Employer Provided Private Coverage__, __Education Levels__, __Log of Percent Black__,
__Log of Median Income__.

$$
Death Rate = 470.47 + 0.23\ IncidenceRate -0.25\ Pecent Employed\_Over16 + 0.29\ PercentUnemployed\_Over16 \\- 0.32\  PercentPrivateCoverage  +0.21\ Percent Employer Provided Private Coverage \\-10.05\ Education Levels +0.90\ Log PercentBlack
-32.39\ Log Median Income
$$
The two age variables and Average Household Size are removed from the model. This agrees with our EDA which showed that they have very close to zero correlation coefficient with Death Rate.
Both employment variables and two out of three healthcare coverage variables are included in this model. We believe this is reasonable because although they showed evidence of collinearity/multicollinearity, we did not have strong arguments to remove any of them. Therefore, we agreed with the variable selection suggested by the Lasso Regression.

Most predictor estimates are smaller than one. However the estimates for Education Levels and Log Median Income are -10.05 and -32.39 respectively which are exceptionally large and negative. This means that they have much larger impact on the predicted death rates than other predictor variables. It makes sense that Median Income has the largest impact because patients in counties with higher median income tend to be able to afford better treatment which reduce mortality rates.

We calculated the R-squared using Leave-One-Out Cross Validation. The R-squared for this Lasso Regression model is 0.4441.
 
```{r LASSO_RMSE, include=FALSE, cache=TRUE}
numCores <- detectCores()
registerDoParallel(numCores) 

n <- dim(cancer)[1]
lasso.dev.ratios <- rep(NA, n)
lasso.dev.ratios1 <- rep(NA, n)
lm.lasso.cv <- cv.glmnet(cancer.lasso.dm, cancer$deathRate, alpha=0, nfolds=n, parallel=TRUE)

lm.lasso.cv$lambda.1se

for (i in 1:n) {
  lm.lasso.1se <- glmnet(cancer.dm[-i,], cancer$deathRate[-i], alpha = 0, 
               lambda = lm.lasso.cv$lambda.1se)
  
  
  lasso.dev.ratios1[i] <- lm.ridge.1se$dev.ratio
  # lm.residuals <- predict(lm.ridge.1se, newx=cancer.dm[-i, ]) - cancer$deathRate[-i]
  # dev.ratios[i] <- 1 - sum(lm.residuals^2)/sum((cancer$deathRate[-i] -mean(cancer$deathRate[-i]))^2) 
  
}
mean(lasso.dev.ratios1)

for (i in 1:n) {
  lm.lasso.min <- glmnet(cancer.dm[-i,], cancer$deathRate[-i], alpha = 0, 
               lambda = lm.lasso.cv$lambda.min)
  
  
  lasso.dev.ratios1[i] <- lm.ridge.1se$dev.ratio
  # lm.residuals <- predict(lm.ridge.1se, newx=cancer.dm[-i, ]) - cancer$deathRate[-i]
  # dev.ratios[i] <- 1 - sum(lm.residuals^2)/sum((cancer$deathRate[-i] -mean(cancer$deathRate[-i]))^2) 
  
}
mean(lasso.dev.ratios1)



```


## Statistical Interpretation and Validation

```{r ResidualPlot,echo=FALSE}

# So wanna make a plot of residuals vs fitteds
library(ggplot2)

multResidualPlot <- function(residual.list, fitted.list, models) {
  
  
  # a <- data.frame(x=fitted.list[[1]], y=residual.list[[1]], col=rep('blue', times=length(fitted.list[[1]])))
  a <- data.frame()
  for (i in 1:length(models)) {
    x <- fitted.list[[i]] 
    y <- residual.list[[i]]
    model <- rep(models[i], times=length(x))
    
    df.temp <- data.frame(x, y, model)
    colnames(df.temp) <- c("x", "y", "model")
    a <- rbind(a, df.temp)
  }
  mrp <- ggplot(a, aes(x=x, y=y, colour=model)) + 
    geom_point(alpha=0.3, size=0.75) + geom_smooth() +
    labs(x="Fitted Values", y="Residuals", title="Residuals vs Fitted Values", model="Models")
  return(mrp)
}

lm.ridge.residuals <- cancer$deathRate - lm.ridgefitted
residual.list <- list(
  hybridoptimalBIC$residuals,
  lm.ridge.residuals,
  lm.lasso.1se.residuals
)

fitted.list <- list(
  hybridoptimalBIC$fitted.values,
  lm.ridgefitted,
  lm.lasso.1se.fitted
)
mrp <- multResidualPlot(residual.list, fitted.list,
                 c("Hybrid Optimal BIC", "RIDGE", "LASSO"))
mrp
```

We see from the plot above that all three models appear to exhibit constant variance with an even spread of points as well as having a mean of zero with the distributions symmetrical about zero. Thus satisfying our key linear regression assumptions of homeoscedasticity and residuals having a mean of zero.

```{r ResidualPlot 2, eval=FALSE, include=FALSE}
library(plotly)
### INTERACTIVE RESIDUAL
ggplotly(mrp)
```

Produce map of each states average residual value for the LASSO model.

```{r Average, include=FALSE}
cancermodel2 = separate(cancer,"Geography",into=c("County","State"),sep=",")
#average for each state
averageresidual=round(tapply(lm.lasso.1se.residuals,cancermodel2$State,mean)[-c(2,12)],0)
states <- map_data("state")
averagedf <- data.frame(region=unique(states$region), averageresidual)
mergedf <- merge(states, averagedf, by="region")
statenames <- data.frame(region=tolower(state.name), clong=state.center$x, clat=state.center$y)
statenames <- merge(statenames, averagedf, by="region")
statenames$lab <- paste(c(state.abb, 'DC')[match(statenames$region, c(tolower(state.name), 'District of Columbia'))], '\n', statenames$averageresidual, sep="")
```

```{R USMAP, echo=FALSE, cache=TRUE}
qplot(long, lat, data=mergedf, geom="polygon", fill=averageresidual, group=region) + 
  scale_fill_gradient(averageresidual,low="yellow",high="red") +
  geom_text(data=statenames,aes(clong,clat,label=statenames$lab,inherit.aes = FALSE,label.size=0.001)) +
   theme_void() + theme(legend.title = element_blank(),plot.title = element_text(hjust = 0.5))+
 + ggtitle("Heatmap of Average Residuals of US States") 
```

# Author Contributions

# References 

<div id="refs"></div>


\pagebreak
# Appendix

2.1 Outcomes of EDA

2.1.1 Missing Or Incorrect Values

\scriptsize
```{r impute A, eval=FALSE}
# Impute the missing data seen in the data set
mod1=lm(PctEmployed16_Over~+incidenceRate+medIncome+binnedInc+povertyPercent+MedianAgeMale+MedianAgeFemale+AvgHouseholdSize
        +PercentMarried+PctUnemployed16_Over+PctPrivateCoverage+PctEmpPrivCoverage+PctPublicCoverage+PctBlack
        +PctMarriedHouseholds+Edu18_24,cancer)
missdf = cancer[which(is.na(cancer$PctEmployed16_Over)==TRUE),]
imputed = predict(mod1,missdf)
cancer[which(is.na(cancer$PctEmployed16_Over)==TRUE),"PctEmployed16_Over"] = imputed
# Scale average household sizes that are less than 1 by 100
cancer[which(cancer$AvgHouseholdSize < 1), ]$AvgHouseholdSize <- 
  100*cancer[which(cancer$AvgHouseholdSize < 1), ]$AvgHouseholdSize
hist(cancer$AvgHouseholdSize, breaks=30, xlab="AvgHouseholdSize", main="Histogram of AvgHouseholdSize")
```
\normalsize

2.1.2 Outliers

\scriptsize
```{r incidenceRateRemoval A, eval=FALSE, fig.asp=0.5, fig.cap="Cook's distance plots with one variable(Left) and all variables(Right)"}
# Cook's distance Plot
par(mfrow=c(1,2))
plot(lm(deathRate ~ incidenceRate,data=cancer),4)
plot(lm(deathRate ~ .,data=cancer[-c(1,4)]),4)
# Removing outlier incidence rate 'Williamsburg City, Virginia'
cancer <- filter(cancer, incidenceRate <= 850)
```
\normalsize

2.1.3 Transformations

\scriptsize
```{r transformations A, eval=FALSE}
# Log transforming the heavily skewed distributions of PctBlack and medIncome
cancer$logpctblack = log(cancer$PctBlack+0.05)
cancer$logmedincome = log(cancer$medIncome)
# Showing improvements in homoscedasticity in PctBlack
# Similar plots can be produced for medIncome
par(mfrow=c(1,2))
plot(lm(deathRate~PctBlack,data=cancer),1)
plot(lm(deathRate~logpctblack,data=cancer),1)
```
\normalsize

2.2 Modelling Approach and Variable Selection

2.2.1 AIC and BIC Forward and Backward Variable Selection

\scriptsize
```{r stepwise A, eval=FALSE}
# We perform stepwise regression for BIC
cancermodel <- cancer %>% select(
  !c("Geography", "medIncome", "binnedInc", "PctBlack"))
c0=lm(deathRate~1,cancermodel)
cmax=lm(deathRate~.,cancermodel)
forwardoptimalBIC = step(c0,direction="forward",
scope=list("lower"=c0,"upper"=cmax),trace=0,k=log(3045))
backwardoptimalBIC = step(cmax,direction="backward",
scope=list("lower"=c0,"upper"=cmax),trace=0,k=log(3045))
hybridoptimalBIC = step(c0,direction="both",
scope=list("lower"=c0,"upper"=cmax),trace=0,k=log(3045))
# An example code for summary and coefficient of models
summary(hybridoptimalBIC)
coef(hybridoptimalBIC)
# Computing the VIF of the BIC stepwise regression model
vif(hybridoptimalBIC)
library(caret)
#specify the cross-validation method
#fit a regression model and use LOOCV to evaluate performance
loocv <- function(lm1, data=cancer) {
  ctrl <- trainControl(method = "LOOCV")
  xnam <- names(lm1$coefficients)[-1]
  fmla <- as.formula(paste("deathRate ~ ", paste(xnam, collapse= "+")))
  model <- train(fmla, data = data, method = "lm", trControl = ctrl)
  return(model)
}
hybridoptimalBIC.loocv <- loocv(hybridoptimalBIC,data=cancermodel)
```
\normalsize

2.2.2 RIDGE Regression

\scriptsize
```{r Ridge 1 A, eval=FALSE}
library(glmnet)
# Producing a 1-standard-error-lambda RIDGE regression model
# We also used similar codes for LASSO regression
cancer.dm <- cancer %>% 
  select(!c("Geography", "medIncome", "binnedInc", "PctBlack", "deathRate")) %>%
  data.matrix()
lm.ridge <- glmnet(cancer.dm, cancer$deathRate, alpha=0)
lm.ridge.cv <- cv.glmnet(cancer.dm, cancer$deathRate, alpha=0)
# Create Model Plot Func
traceLogLambda <- function(lm1, lm1.cv, ylim=NULL, sub=NULL) {
  plot(lm1,"lambda",label = T, ylim=ylim)
  abline(v=log(lm1.cv$lambda.1se),col="red")
  abline(v=log(lm1.cv$lambda.min),col="blue")
  legend("bottomright",legend=c("Minimum lambda", "1 standard error larger lambda"),lty=c(1,1),col=c("blue","red"), ins=0.05)
  title(sub=sub)
}
traceLogLambda(lm.ridge, lm.ridge.cv, ylim=c(-20, 1), sub="RIDGE trace against log(lambda)")
lm.ridge.1se <- glmnet(cancer.dm, cancer$deathRate, alpha = 0, 
               lambda = lm.ridge.cv$lambda.1se)
lm.ridgefitted <- predict(lm.ridge.1se, newx=cancer.dm)
scatter.smooth(cancer$deathRate - lm.ridgefitted, x=lm.ridgefitted,
               xlab="Fitted", ylab="Residuals", 
               sub="Residuals vs Fitted for RIDGE Model")
# Leave-one-out cross-validation for RIDGE Regression
# Calculate R-squared statistics
# We also performed the same procedures for LASSO Regression
library(parallel)
library(foreach)
library(doParallel)
numCores <- detectCores()
registerDoParallel(numCores) 
n <- dim(cancer)[1]
dev.ratios <- rep(NA, n)
dev.ratios1 <- rep(NA, n)
lm.ridge.cv <- cv.glmnet(cancer.dm, cancer$deathRate, alpha=0, nfolds=n, parallel=TRUE)
lm.ridge.cv$lambda.1se
for (i in 1:n) {
  lm.ridge.1se <- glmnet(cancer.dm[-i,], cancer$deathRate[-i], alpha = 0, 
               lambda = lm.ridge.cv$lambda.1se)
  dev.ratios1[i] <- lm.ridge.1se$dev.ratio
}
mean(dev.ratios1)
##Produce column of table for coefficients table
library(knitr)
# This produces a table of parameter estimate for RIDGE model
# We also produced similar table for LASSO model and combined these with the stepwise coefficients into a 'kable'
a <- data.frame(sapply(round(coef(lm.ridge.1se), 3), FUN=identity))
colnames(a) <- "Parameter Estimates"
rownames(a) <- rownames(round(coef(lm.ridge.1se), 3))
```
\normalsize

2.2.3 LASSO Regression

\scriptsize
```{r Lasso cv A, eval=FALSE}
# Produce a LASSO Regression model
# Produce a plot of mean-squared error against log(lambda)
set.seed((934))
lm.lasso <-glmnet(cancer.lasso.dm,cancer$deathRate,alpha=1)
lm.lasso.cv <- cv.glmnet(cancer.lasso.dm,cancer$deathRate,alpha=1)
plot(lm.lasso.cv)
abline(v=log(lm.lasso.cv$lambda.1se),col="red")
abline(v=log(lm.lasso.cv$lambda.min),col="blue")
legend("topright",legend=c("Minimum lambda", "1 standard error larger lambda"),lty=c(1,1),col=c("blue","red"), ins=0.1)
lm.lasso.cv$lambda.1se
lm.lasso.1se <- glmnet(cancer.lasso.dm,cancer$deathRate,lambda = lm.lasso.cv$lambda.1se,alpha=1)
lm.lasso.1se.fitted <- predict(lm.lasso.1se, newx=cancer.lasso.dm)
lm.lasso.1se.residuals <- cancer$deathRate - lm.lasso.1se.fitted
# Produce a plot that shows the trace of each parameter estimate for different lambda
lm.lasso.scaled<-glmnet(scale(cancer.lasso.dm),cancer$deathRate,alpha=1)
traceLogLambda(lm.lasso.scaled,lm.lasso.cv,ylim=c(-10,10), sub="LASSO trace against log(lambda)")
```
\normalsize

2.4 Statistical Interpretation and Validation

\scriptsize
```{r ResidualPlot A,eval=FALSE}
# Create plot of Residual vs Fitted
library(ggplot2)
multResidualPlot <- function(residual.list, fitted.list, models) {
  a <- data.frame()
  for (i in 1:length(models)) {
    x <- fitted.list[[i]] 
    y <- residual.list[[i]]
    model <- rep(models[i], times=length(x))
    df.temp <- data.frame(x, y, model)
    colnames(df.temp) <- c("x", "y", "model")
    a <- rbind(a, df.temp)
  }
  mrp <- ggplot(a, aes(x=x, y=y, colour=model)) + 
    geom_point(alpha=0.3, size=0.75) + geom_smooth() +
    labs(x="Fitted Values", y="Residuals", title="Residuals vs Fitted Values", model="Models")
  return(mrp)
}
lm.ridge.residuals <- cancer$deathRate - lm.ridgefitted
residual.list <- list(hybridoptimalBIC$residuals, lm.ridge.residuals, lm.lasso.1se.residuals)
fitted.list <- list(hybridoptimalBIC$fitted.values, lm.ridgefitted, lm.lasso.1se.fitted)
mrp <- multResidualPlot(residual.list, fitted.list, c("Hybrid Optimal BIC", "RIDGE", "LASSO"))
```
\normalsize

Produce map of each states average residual value for the LASSO model.

\scriptsize
```{r Average A, eval=FALSE}
#average for each state
averageresidual=round(tapply(lm.lasso.1se.residuals,cancermodel2$State,mean)[-c(2,12)],0)
states <- map_data("state")
averagedf <- data.frame(region=unique(states$region), averageresidual)
mergedf <- merge(states, averagedf, by="region")
statenames <- data.frame(region=tolower(state.name), clong=state.center$x, clat=state.center$y)
statenames <- merge(statenames, averagedf, by="region")
statenames$lab <- paste(c(state.abb, 'DC')[match(statenames$region, c(tolower(state.name), 'District of Columbia'))], '\n', statenames$averageresidual, sep="")
#Produce heatmap of average residual
qplot(long, lat, data=mergedf, geom="polygon", fill=averageresidual, group=region) + 
  scale_fill_gradient(averageresidual,low="yellow",high="red") +
  geom_text(data=statenames,aes(clong,clat,label=statenames$lab,inherit.aes = FALSE,label.size=0.001)) +
   theme_void() + theme(legend.title = element_blank(),plot.title = element_text(hjust = 0.5))+
 + ggtitle("Heatmap of Average Residuals of US States") 
```
\normalsize
